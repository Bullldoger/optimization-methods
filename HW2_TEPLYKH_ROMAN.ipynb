{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:\n",
    "#### Answer: k = n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "#### Answer: dimension of M is (n, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Derive second to fifth terms in Taylor series expansion for the natural logarithm with respect to point $ a \\geq 0 $\n",
    "#### Solution: \n",
    "$$\n",
    "log(x) = log(a) + \\dfrac{1}{a} (x - a) - \n",
    "         \\dfrac{1}{2 a^2} (x - a)^2 + \\\\\n",
    "         \\dfrac{2}{6 a^3} (x - a)^3 -\n",
    "         \\dfrac{6}{24 a^4} (x - a)^4 + o((x - a)^4)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Find minimum (i.e. both point $ x^{*} $ and function value $ f^{*} = f(x^{*})) $ of function with respect\n",
    "to parameters $ a, b, c $:\n",
    "$$ f(x) = a x^2 + b x + c $$\n",
    "\n",
    "#### Solution:\n",
    "$$\n",
    "\\dfrac{d f}{d x}(x) = 2 a x + b = 0 \\implies x^{*} = -\\dfrac{b}{2a} \\\\\n",
    "\\text{ Substitute } x^{*} to f(x) \\implies f(x^{*}) = a (-\\dfrac{b}{2a})^2 - \\dfrac{b}{2a} b + c = \\dfrac{b}{4 a^3} - \\dfrac{b^2}{2a} + c\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "What are dimensions of gradient of a function $ h(x) = f(Ax) $, constructed of function $ f : R^m \\rightarrow R $ and matrix $ A \\in R^{m \\times k} $ .\n",
    "#### Answer: $$ \\nabla h(x) \\in R^{m} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "Prove that for a strongly convex function with parameter $ μ $ holds:\n",
    "$$ \\dfrac{\\mu}{2} || x - x^{*} ||_2^2 \\leq f(x) - f^{*} $$\n",
    "\n",
    "#### Proof\n",
    "$$\n",
    "f^{*} = f(x^{*}) \\\\\n",
    "f(x) - f(x^{*}) = \\left [ f(x) = f(x^{*}) + f'(x^{*}) (x - x^{*}) \\\\\n",
    "+ \\dfrac{f''(x^{*})}{2} (x - x^{*})^2 + o( ||x - x^{*}||_2^2 ) \\\\ \\text{Derivative at } x^{*} \\text{ is 0} \\right ] \\implies \\\\\n",
    "f(x) - f(x^{*}) = \\dfrac{f''(x^{*})}{2} (x - x^{*})^2 + o( ||x - x^{*}||_2^2 )\n",
    "$$\n",
    "Moreover, $ f $ strongly convex if and only if $ f''(x) \\geq m > 0 $ for all x $ \\implies $\n",
    "$$\n",
    "\\dfrac{f''(x^{*})}{2} (x - x^{*})^2 + o( ||x - x^{*}||_2^2 ) |_{f''(x^{*}) = \\mu} = \\dfrac{\\mu}{2} || x - x^{*} ||_2^2 + o( ||x - x^{*}||_2^2 )\n",
    "\\implies \\dfrac{\\mu}{2} || x - x^{*} ||_2^2 \\leq f(x) - f(x^{*})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "Find conjugate $ f^{*} (y) $ and it's domain for function $$ f(x) = \\dfrac{1}{x} $$ with <strong>dom</strong> $ f = \\{ x : x > 0 \\} $\n",
    "\n",
    "#### Solution\n",
    "$$\n",
    "f^{*} (y) \\doteq sup_{x \\in \\textbf{dom } f} \\left ( y^{T} x - f(x) \\right ) \\\\\n",
    "f^{*} (y) \\doteq sup_{x \\in \\textbf{dom } f} \\left ( y^{T} x - \\dfrac{1}{x} \\right )\n",
    "$$\n",
    "Here, dimension of domain space is 1, thus \n",
    "$$\n",
    "f^{*} (y) \\doteq sup_{x \\in \\textbf{dom } f} \\left ( y x - \\dfrac{1}{x} \\right ) \\implies \\dfrac{d \\left ( y x - \\dfrac{1}{x} \\right ) }{d x} = y + \\dfrac{1}{x^2} = 0 \\\\\n",
    "y + \\dfrac{1}{x^2} = 0 \\implies -y = \\dfrac{1}{x^2} \\implies x = \\dfrac{1}{\\sqrt{-y}}\n",
    "$$\n",
    "for all $ y < 0 $\n",
    "$$\n",
    "f^{*} (y) = y \\dfrac{1}{\\sqrt{-y}} - \\sqrt{-y}, \\textbf{ dom } f^* = \\{ y < 0 \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 \n",
    "\n",
    "Given conjugate function for $ f^{*} (y) $ for $ f(x) $, find conjugate function and its domain for \n",
    "$$\n",
    "g(x) = f(x) + (c, x) + d \\\\ c \\in R^{n}, d \\in R\n",
    "$$\n",
    "\n",
    "#### Solution\n",
    "$$\n",
    "g^{*}(y) = sup_{x \\in \\textbf{dom } f} \\left ( y^{T} x - g(x) \\right ) = \\\\ = sup_{x \\in \\textbf{dom } f} \\left ( y^{T} x - f(x) - (c, x) - d \\right )\n",
    "$$\n",
    "On the other hand, we have\n",
    "$$\n",
    "f^{*} (y) = sup_{x \\in \\textbf{dom } f} \\left ( y^{T} x - f(x) \\right ) \\implies  \\\\ g^{*}(t) |_{t = y - c} = sup_{x \\in \\textbf{dom } f} \\left ( t^{T} x - f(x) \\right ) - d = f^{*} (t) - d = \\\\ \\implies g^{*} (y) = f^{*} (y - c) - d\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "Derive gradient and hessian for $ f(x) = (c, x)^2, x \\in R^n $\n",
    "\n",
    "#### Solution\n",
    "$$\n",
    "f(x) = (c, x)^2 \\\\\n",
    "\\nabla f(x) = 2 \\left ( c^\\top \\cdot x \\right ) c \\\\\n",
    "\\nabla^2 f(x) = 2 \\left ( c \\cdot c^\\top \\right )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10\n",
    "\n",
    "Derive Hessian matrix for $ f(x) = g(A x + b) $, assuming diffenetiable $ g : R^m \\rightarrow R $, with dimensions $ A \\in R^{m \\times n}, x \\in R^n $\n",
    "\n",
    "$ \\circ $ - Hamadard product (elementwise)\n",
    "\n",
    "#### Solution\n",
    "$$\n",
    "\\nabla_x f(x) = \\nabla_x g(A x + b)\n",
    "$$\n",
    "Let $ k_i $ - i-th component of $ g(.) $, thus\n",
    "$$\n",
    "\\nabla_x f_i = \\sum_{j = 1}^{m} \\dfrac{\\partial g}{\\partial k_j} \\dfrac{\\partial k_j}{\\partial x_i} = \\sum_{j = 1}^{m} \\dfrac{\\partial g}{\\partial k_j} \\left ( \\dfrac{\\partial }{\\partial x_i} \\sum_{k = 1}^{n} a_{j, k} x_k + b_j \\right ) = \\sum_{j = 1}^{m} \\dfrac{\\partial g}{\\partial k_j} a_{j, i}\n",
    "$$\n",
    "or in matrix form\n",
    "$$\n",
    "\\nabla_x f(x) = div_{y = A x + b} g(y) \\circ A^\\top \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\vdots \\\\\n",
    "    1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "The next subtask, $ \\nabla_x^2 f(x) $:\n",
    "$$\n",
    "\\nabla_x^2 f(x)_{i, j} = \\sum_{l = 1}^m \\sum_{p = 1}^m \\dfrac{\\partial^2 g}{\\partial k_l \\partial k_p} \\dfrac{\\partial k_l}{\\partial x_i}\\dfrac{\\partial k_p}{\\partial x_j} = \\sum_{l = 1}^m \\sum_{p = 1}^m \\left [ \\dfrac{\\partial^2 g}{\\partial k_l \\partial k_p} \\left ( \\dfrac{\\partial }{\\partial x_i} \\sum_{t = 1}^n a_{l, t} x_t + b_k \\right ) \\left ( \\dfrac{\\partial }{\\partial x_j} \\sum_{t = 1}^n a_{p, t} x_t + b_k \\right ) \\right ] = \\sum_{l = 1}^m \\sum_{p = 1}^m \\left [ \\dfrac{\\partial^2 g}{\\partial k_l \\partial k_p} a_{l, i} a_{p, j} \\right ] \\\\\n",
    "\\nabla_x^2 f(x) = (\\nabla_{y = A x + b} \\cdot \\nabla_{y = A x + b}^\\top) g(y) \\circ \\left ( A^\\top \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\vdots \\\\\n",
    "    1\n",
    "\\end{bmatrix} \\left ( {  A^\\top \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\vdots \\\\\n",
    "    1\n",
    "\\end{bmatrix}} \\right)^\\top \\right )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11\n",
    "\n",
    "Prove sufficient first order optimality condition for (everywhere) differentiable convex function $ f(x) $ : If $ \\nabla f(x^*) = 0 $, then $ x^* $ is a global minimum of $ f $”.\n",
    "\n",
    "#### Solution\n",
    "From \"Extra task 1(3)\" we have:\n",
    "$$\n",
    "f(y) \\geq f(x) + (\\nabla f(x), y - x) + \\mu || x - y ||_2^2\n",
    "$$\n",
    "All we need it let $ x = x^* $:\n",
    "$$\n",
    "f(y) \\geq f(x^*) + (\\nabla f(x^*), y - x) + \\mu || x - y ||_2^2 \\implies f(y) \\geq f(x^*) + \\mu || x - y ||_2^2 \\implies f(y) > f(x^*)\n",
    "$$\n",
    "For all $ y \\in \\textbf{ dom } f $ and $ x^* \\neq y $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12\n",
    "\n",
    "Solve optimal step-size problem for the quadratic function, with symmetric positive definite matrix $ A > 0, A \\in R^{n \\times n} $, and $ x, b, d \\in R^n $.\n",
    "Your goal is to find optimal $ \\gamma^{*} $ for given $ A, b, d, x $.\n",
    "The resulting expression must be written in terms of inner products (..., ...) \n",
    "$$\n",
    "f(\\gamma) = (A(x + \\gamma d), x + \\gamma d) + (b, x + \\gamma d) \\rightarrow min_{\\gamma \\in R} \n",
    "$$\n",
    "\n",
    "#### Solution\n",
    "$$\n",
    "f(\\gamma) = (A(x + \\gamma d), x + \\gamma d) + (b, x + \\gamma d) \\rightarrow min_{\\gamma \\in R} \\\\\n",
    "\\dfrac{d f(\\gamma)}{d \\gamma} = \\dfrac{d }{d \\gamma} \\left ( x^T A x + \\gamma x^T d + \\gamma d^T A x + \\gamma^2 d^T A d + b^T x + \\gamma b^T d \\right ) = \\\\ = x^T d + d^T A x + 2 \\gamma d^T A d + b^T d = 0 \\\\\n",
    "\\gamma = -\\dfrac{b^T d + x^T d + d^T A x}{2 d^T A d}\n",
    "\\\\ \\gamma = -\\dfrac{(b + x + Ax, d)}{2 (A d, d) }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13\n",
    "\n",
    "Derive subgradient (subdifferential) for the function $ f(x) = \\left [ x^2 - 1 \\right ]_{+}, x \\in R $ subgradient method).\n",
    "\n",
    "#### Solution\n",
    "By definition \n",
    "$$ \n",
    "\\partial f(x) = \\{ g | g^T (y - x) \\leq f(y) - f(x), y \\in \\textbf{dom } f \\} \\\\\n",
    "f(x) = \\left [ x^2 - 1 \\right ]_{+} = \\begin{cases}\n",
    "    0, -1 < x < 1, \\\\\n",
    "    x^2 - 1, \\{ x \\ge 1 \\} \\bigcup \\{ x \\le -1 \\}\n",
    "\\end{cases}\n",
    "$$\n",
    "$ f(x) $ not differentiable at $ x = -1, x = 1 $, thus:\n",
    "$$\n",
    "\\implies\n",
    "\\partial f(x) = \\begin{cases}\n",
    "    0, -1 < x < 1, \\\\\n",
    "    \\partial (x^2 - 1), \\{ x > 1 \\} \\bigcup \\{ x < -1 \\}\n",
    "\\end{cases} = \\begin{cases}\n",
    "    0, -1 < x < 1, \\\\\n",
    "    2x, \\{ x > 1 \\} \\bigcup \\{ x < -1 \\}, \\\\\n",
    "    [0, 2], x = 1, \\\\\n",
    "    [-2, 0], x = -1\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "<p align = 'left'>\n",
    "$\n",
    "1. f( \\alpha x + (1 - \\alpha) y ) \\leq \\alpha f(x) + ( 1 - \\alpha) f(y) - \\mu \\dfrac{\\alpha ( 1 - \\alpha )}{2} || x - y ||_2 \\\\\n",
    "3. f(y) \\geq f(x) + (\\nabla f(x), y - x) + \\mu || x - y ||_2^2 \\\\\n",
    "4. (\\nabla f(x) - \\nabla f(y), x - y) \\geq \\mu || x - y ||_2\n",
    "$\n",
    "</p>\n",
    "\n",
    "- a) Derive 4th definition of strong convexity from the 3rd one (function is differentiable).\n",
    "- b) Derive 3rd definition of strong convexity from the 1st one (function is differentiable). \n",
    "Hint: you may need limits.\n",
    "\n",
    "#### Solution (b)\n",
    "\n",
    "$$\n",
    "f( \\alpha x + (1 - \\alpha) y ) \\leq \\alpha f(x) + ( 1 - \\alpha) f(y) - \\mu \\dfrac{\\alpha ( 1 - \\alpha )}{2} || x - y ||_2 = \\\\ =\n",
    "\\left [ f(y) = f(x) + \\nabla f(x) (y - x) + \\dots \\right ] = \\alpha f(x) + ( 1 - \\alpha) \\left ( f(x) + \\nabla f(x) (y - x) + \\dfrac{\\nabla^2 f(x)}{2} (y - x)^2 + o( || y - x ||_2^2 ) \\right ) - \\mu \\dfrac{\\alpha ( 1 - \\alpha )}{2} || x - y ||_2 = \\\\\n",
    "f( \\alpha x + (1 - \\alpha) y ) \\leq \\alpha f(x) + ( 1 - \\alpha) \\left ( f(x) + \\nabla f(x) (y - x) + \\dfrac{\\nabla^2 f(x)}{2} (y - x)^2 + o( || y - x ||_2^2 ) \\right ) - \\mu \\dfrac{\\alpha ( 1 - \\alpha )}{2} || x - y ||_2 \\\\\n",
    "f( \\alpha x + (1 - \\alpha) y ) \\leq f(x) + ( 1 - \\alpha) \\left (\\nabla f(x) (y - x) + o( || y - x ||_2^2 ) \\right ) + (1 - \\alpha) \\dfrac{\\nabla^2 f(x)}{2} (y - x)^2- \\mu \\dfrac{\\alpha ( 1 - \\alpha )}{2} || x - y ||_2\n",
    "$$\n",
    "Let $ \\alpha = 0 $, thus:\n",
    "$$\n",
    "f( y ) \\leq f(x) + \\nabla f(x) (y - x) + \\dfrac{\\nabla^2 f(x)}{2} (y - x)^2 \\leftrightarrow f( y ) \\leq f(x) + \\nabla f(x) (y - x) + \\mu (y - x)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2(a)\n",
    "\n",
    "Solve Least Squares problem (find $ x^{*} $ and $ f^{*} $) $ min_x || Ax - b ||_2 $\n",
    "b) $ A \\in R^{n \\times n}, b \\in R^m, m > n $, $ det A \\neq 0 $\n",
    "\n",
    "#### Solution\n",
    "\n",
    "$$\n",
    "f(x) = || A x - b ||_2 = (A x - b)^\\top (A x - b) = (x^\\top A^\\top - b^\\top) (A x - b) = x^\\top A^\\top A x - x^\\top A^\\top b - b^\\top A x + b^\\top b \\\\\n",
    "min_x f(x) = min_x \\left [ x^\\top A^\\top A x - x^\\top A^\\top b - b^\\top A x + b^\\top b \\right ] = min_x \\left [ x^\\top A^\\top A x - x^\\top A^\\top b - b^\\top A x \\right ] \\\\\n",
    "\\dfrac{d f(x)}{d x} = \\dfrac{d}{dx} \\left ( x^\\top A^\\top A x - x^\\top A^\\top b - b^\\top A x + b^\\top b \\right ) = x^\\top A A^\\top + x^\\top A A - b^\\top A^\\top - b^\\top A = \\vec{0} \\leftrightarrow x^\\top (A A^\\top + A A ) = b^\\top A + b^\\top A^\\top \\\\ \n",
    "x^\\top = b^\\top A^{-1} \\leftrightarrow x = (A^{-1})^\\top b\n",
    "$$\n",
    "Optimal point $ x^* $ to $ f(x) \\implies f^* $:\n",
    "$$\n",
    "f(x) = || A x - b ||_2 = f(x) = || A (A^{-1})^\\top b - b ||_2 = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2(b)\n",
    "\n",
    "Solve Least Squares problem (find $ x^{*} $ and $ f^{*} $) $ min_x || Ax - b ||_2 $\n",
    "b) $ A \\in R^{m \\times n}, b \\in R^m, m > n $, assuming A has full column rank, i.e. $ A^\\top A $ is non-singular.\n",
    "\n",
    "Hint: if $ f(x) \\geq 0 $, then $ (min_x f(x))^2 = min_x (f(x)^2) $.\n",
    "\n",
    "#### Solution\n",
    "\n",
    "$$\n",
    "f(x) = || A x - b ||_2 = (A x - b)^\\top (A x - b) = (x^\\top A^\\top - b^\\top) (A x - b) = x^\\top A^\\top A x - x^\\top A^\\top b - b^\\top A x + b^\\top b \\\\ \\implies\n",
    "min_x f(x) = min_x \\left [ x^\\top A^\\top A x - x^\\top A^\\top b - b^\\top A x + b^\\top b \\right ] = min_x \\left [ x^\\top A^\\top A x - x^\\top A^\\top b - b^\\top A x \\right ]\n",
    "$$\n",
    "We have a hint, that: $ f(x) \\geq 0 $, then $ (min_x f(x))^2 = min_x (f(x)^2) $, obviously, $ f(x) \\geq 0 \\implies $\n",
    "$$\n",
    "\\dfrac{d f(x)}{d x} = \\dfrac{d}{dx} \\left ( x^\\top A^\\top A x - x^\\top A^\\top b - b^\\top A x + b^\\top b \\right )^2 = 2 \\left ( x^\\top A^\\top A x - x^\\top A^\\top b - b^\\top A x + b^\\top b \\right ) \\left ( 2 (A x^\\top)^\\top A - (A^T b) - (A^T b) \\right ) = 0 \\implies \\\\\n",
    "\\begin{cases}\n",
    "    x^\\top A^\\top A x - x^\\top A^\\top b - b^\\top A x + b^\\top b = 0, \\text{ hasn't solution } \\\\\n",
    "    2 (A x^\\top)^\\top A - (A^T b) - (A^T b) = \\vec{0}\n",
    "\\end{cases} \\implies\n",
    "2 (A x^\\top)^\\top A - (A^T b) - (A^T b) = \\vec{0} \\leftrightarrow 2 x A^\\top A - 2 (A^T b) = \\vec{0} \\\\ x = ((A^\\top A)^{-1}) A^\\top b\n",
    "$$\n",
    "As it was in the hint, we have optimal $ x^{*} $ and we can substitute it to $ f(x) $\n",
    "$$\n",
    "f(x) = (A x - b)^\\top (A x - b) = (A (((A^\\top A)^{-1}) A^\\top b - b)^\\top (A ((A^\\top A)^{-1}) A^\\top b - b) = || A ((A^\\top A)^{-1}) A^\\top b - b ||_2\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
